{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91687fb0",
   "metadata": {},
   "source": [
    "## Deep Residual Networks (ResNets)\n",
    "\n",
    "Deep Residual Networks, CNN tabanlı bir yapıdır. CNN ile Deep Residual Networks arasındaki farklara değinilecektir. \n",
    "\n",
    "Deep Residual Networks'ü veri seti üzerinde uygulayacağız ve bu işlemler Pytorch kütüphanesi kullanılarak gerçekleştirilecektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48c2bd",
   "metadata": {},
   "source": [
    "## CNN vs Deep Residual Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f041dd78",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"r1.png\" align = \"left\" style=\"width:500px;height:900px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d71a2",
   "metadata": {},
   "source": [
    "Yukarıda VGG-19, 34-layer plain ve 34-layer residual isimlerinde 3 farklı neural network yapısını görmekteyiz. VGG-19'u Transfer Learning konusunda göreceğiz. 34-layer residual ifadesinde bulunan residual, resnets'dir. 34-layer residual, 152 layer'dan oluşan bir neural network'tür.\n",
    "\n",
    "34-layer plain bir convotional neural network yapısı değildir fakat bunu convotional neural network gibi düşüneceğiz. Yani 34-layer plain'i bir CNN gibi düşünün. Buradaki amaç, CNN'in çok derin olduğunu göstermektir. Yani fazladan bir sürü layer eklenebildiğini göstermek için bahsedilmiştir.\n",
    "\n",
    "Görselde de görüleceği üzere CNN'in (ortadaki) ResNets yapısından (sondaki) farkı, input'un output'a sağ taraftaki ok şeklinde eklenmesidir. Bu işlem tekrarlanarak ResNets yapısı oluşturulmuştur. \n",
    "\n",
    "<font color=\"Chocolate\"><br>\n",
    "ResNets ile CNN'de derinlere inildikçe ortaya çıkan Vanishing Gradient problemi ortadan kaldırılmıştır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fcb88d",
   "metadata": {},
   "source": [
    "## Vanishing Gradient Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d9000",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"r2.png\" style=\"width:600px;height:300px\"/>\n",
    "\n",
    "Yukarıdaki görseli açıklayayım.\n",
    "kedi ve köpek resimlerinden oluşan bir veri setini classification yapmak isteyelim. nxn'lik bir input layer vardır. Bu weight'ler ile 1.hidden layer'a bağlıdır. Toplamda 3 tane hidden layer ve 1 tane de output layer olsun.\n",
    "\n",
    "1. hidden layer, low layer feature'leri öğrenecektir. Yani köşeler, kenarlar, çapraz çizgiler vs. 1.hidden layer'da öğrenilir. 2.hidden layer middle level feature'dir. Burada biraz daha komplex şekiller ortaya çıkar. 3.hidden layer'da dahada karmaşık şeyler öğrenir. Mesela kedinin kuyruğu, kedinin kulağı gibi şeyler öğrenir. 3.hidden layer'a high level feature extract denir.\n",
    "\n",
    "2 tane class değil de, 1000 tane class'ı sınıflandırmak istersek akla ilk gelen hidden layer sayısını artırmaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3167f1",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"r3.png\" align=\"left\" style=\"width:400px;height:200px\"/>\n",
    "\n",
    "High level'a yaklaşıldıkça bilgi kaybı yaşanmaktadır. Yani derin bir network olduğu zaman her adımda high level'ı etkileyen low level bilgisi kaybolmaya başlıyor. Yani çok derinlere gidildikçe low level bilgisi kaybolur. Mesela 1000 tane sınıfı sınıflandırmak için 50 tane layer içeren bir neural network başarısız olabilir, 20 tane layer içeren bir neural network'e göre. Bu low layer'lardaki bilgi kaybetme problemine Vanishing Gradient Problem denir.\n",
    "\n",
    "Yani Vanishing Gradient Problem, bilgi kaybetme problemidir ve bilgi genelde low layer'larda kaybedilmektedir.\n",
    "\n",
    "Gradient, weight'e göre loss'un türevidir. Neural network'te öğrenilen şey weight'lerdir. w = w - learning_rate * gradient 'dir ve burada gradient, d loss / d w şeklinde loss'un weight'lere göre türevidir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3e131",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"r4.png\" align=\"left\" style=\"width:600px;height:400px\"/> \n",
    "Loss'un weight'e göre türevini neural network'ün derinliği belirlemektedir. Gradient her bir layer'dan geçe geçe adım adım ortaya çıkar. Layer sayısı az ise sorun yoktur. İlk önce w2'ye göre olan loss'u bulunur ve daha sonra w1'e göre olan loss'u bulunur. Ve adım adım bunları çarparak ilerleriz. Ama eğer network çok fazla derin ise w1 değeri güncellenemeyecektir. Çünkü \n",
    "w1 = w1 - learning_rate * gradient işleminde learning_rate*gradient kısmı çok küçük bir sayı çıkacaktır ve dolayısıyla ihmal edilebilecektir. Dolayısıyla w1'den ihmal edilebilecek kadar küçük bir sayı çıkarıldığında w1=w1 olacaktır. Ve görüldüğü üzere öğrenme olmamıştır. w1'in güncellenmemiş olması neural network'ün daha önceden öğrendiğini güncelleyememiş olması anlamına gelmektedir. Bu durum şundan kaynaklanmıştır: Network'ün çok derin olmasından dolayı loss'a göre türev alınırken vashing problemi ile karşılaşılmıştır. Gradient yani türev gözden kaybolarak küçücük bir sayı oldu.\n",
    "\n",
    "Tüm bu anlatılanlar Vanishing Gradient Problem'dir. \n",
    "\n",
    "Bu problem Deep Residual Networks yapıları ile çözülebilmektedir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75cc955",
   "metadata": {},
   "source": [
    "## Deep Residual Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38267be",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"r5.png\" align=\"left\" style=\"width:600px;height:400px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e5070",
   "metadata": {},
   "source": [
    "CNN'de yukarıdan aşağıya bir bilgi akışı vardır ve güncellemelerde aşağıdan yukarıya doğru yapılmaktadır. Güncelleme yapılırken her bir layer, bir önceki layer'dan gelen bilgiye bağlıdır. Bilgi akışının sequential olmasından kaynaklı olarak vanshing gradient problem vardır. Yani gradient'leri kaybediyoruz, bilgileri kaybediyoruz. Bunun çözümü olarakta ResNet yapısı ortaya çıkarılmıştır.\n",
    "\n",
    "<br>\n",
    "<img src=\"r6.png\" align=\"left\" style=\"width:600px;height:400px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3485777",
   "metadata": {},
   "source": [
    "Vanished Gradient problemini çözmek için residual connection bağlantısı eklenmiştir. Yukarıdaki görselde bu bağlantı gösterilmiştir. Layer1'den Layer2'ye bir bilgi akışı söz konusudur. Convolution layer vardır. BatchNorm işlemi vardır. BatchNorm, normalizasyon işleminin her bir layer'da yapılmış halidir. Yani her layer'dan sonra aktivasyon fonksiyonuna giriyor ve aktivasyon fonksiyonundan çıkan output normalize edilir. CNN'den tek farkı, residual connection'dan gelen bilgiler ile mavi ve yeşil layer'da elde edilen bilgiler toplanıyor ve Relu aktivasyon fonksiyonuna veriliyor. Residual connection'a short cut'ta denmektedir. CNN'e short cut koyarak ResNet elde edilmiş oluyor. Bu short cut sayesinde bilgi önceki layer'lardan hiçbir işleme uğramadan bir sonraki layer'a aktarılabiliyor. Böylelikle Vanishing Gradient'ten dolayı yaşanan bilgi kaybı önlenmiş oluyor.\n",
    "\n",
    "CNN sonucunda elde edilen f(x) ise ResNet sonucu elde edilen f(x)+x 'dir.\n",
    "\n",
    "Temelde ResNet yapısı yukarıdaki görselde görüldüğü gibidir. Bu yapı basic residual block olarak adlandırılır. ResNet yapısı kurulurken bu bloklar bir araya getirilerek oluşturulur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402fac9",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"r7.png\" align=\"left\" style=\"width:600px;height:800px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5789dab1",
   "metadata": {},
   "source": [
    "Yukarıda görüldüğü üzere siyah kısım bir blok, kırmızı kısım bir bloktur. Bu şekilde bloklar alt alta getirilerek ResNet yapısı oluşturulur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6413006",
   "metadata": {},
   "source": [
    "## IR Pedestrian Projesi: Dataset Tanıtımı ve Proje Raporu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2517d6ea",
   "metadata": {},
   "source": [
    "ResNet uygulaması için Infrared Pedestrian Dataset kullanılacaktır.\n",
    "\n",
    "Infrared, rgb görüntüler değil de ayar kamerayla elde edilmiş görüntüler anlamına gelir. Pedestrian ise yaya anlamına gelmektedir.\n",
    "\n",
    "Bu veri seti şöyle toplanıyor: Bir kamera arabanın üzerine yerleştiriliyor. Bu araba sokaklarda dolaştırılıyor ve preprocessing yapılarak bizlerin kullanabilmesi için veri seti haline getiriliyor.\n",
    "\n",
    "Veri seti içerisinde Pedestrian (yayalar yani insanlar) ve Non-Pedestrian (insan olmayanlar) olmak üzere 2 tane class vardır.\n",
    "Pedestrian class'ından insan bulunan görüntüler vardır ve Non-Pedestrian içerisinde insan olmadığı görüntüler vardır.\n",
    "\n",
    "<br>\n",
    "<img src=\"r8.png\" align=\"left\" style=\"width:600px;height:400px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f7cab",
   "metadata": {},
   "source": [
    "Yukarıda görüldüğü üzere, Train setinde Pedestrian sınıfına ait 10208 tane görüntü vardır. Train setinde Non-Pedestrian sınıfına ait 43390 tane görüntü vardır. Test setinde Pedestrian sınıfına ait 5944 tane görüntü vardır. Test setinde Non-Pedestrian sınıfına ait 22050 tane görüntü vardır.\n",
    "\n",
    "Veri setindeki resimler 64x32 pixels'dir. Yani resimler 64 satır ve 32 sütundan oluşmaktadır.\n",
    "\n",
    "CNN ve ResNet'i pytorch kütüphanesi ile uygulayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ced007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image #Resimleri preprocess yaparken kullanacağız.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time #Algoritmanın ne kadar sürede çalıştığını hesaplamak için kullanacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741632e8",
   "metadata": {},
   "source": [
    "GPU, graifk kartıdır. GPU, neural network yapılarında CPU'dan çok daha hızlı çalışmaktadır. Kodları GPU'da çalıştırarak hız kazanmamız mümkündür. Kodlar default olarak CPU'da çalışmaktadır. GPU'da çalıştırmak için Pytorch kısa bir kod sağlamaktadır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15402ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b071f1d9",
   "metadata": {},
   "source": [
    "Resimleri okumak için bir metod yazalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee46e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #Resimleri klasörden çekerken kullanacağız.\n",
    "def read_images(path, num_img):\n",
    "    array=np.zeros([num_img,64*32])#allocation yapmak için 0'lardan oluşan boş bir array tanımladım.\n",
    "    i=0\n",
    "    for img in os.listdir(path):\n",
    "        img_path = path + \"\\\\\" + img\n",
    "        img = Image.open(img_path, mode=\"r\")\n",
    "        data = np.asarray(img, dtype=\"uint8\") #uint8 tipine dönüşüm sağlanmıştır.\n",
    "        data = data.flatten() #array'de depolayacağımız için düzleştirme işlemi yaptık.\n",
    "        array[i,:] = data\n",
    "        i+=1\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c74c9d",
   "metadata": {},
   "source": [
    "path parametresi ile resimleri okuyacağımız klasörü ve num_img ile kaç tane resim okuyacağımız bilgisini göndereceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67449101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read train negative folder (43390 sample)\n",
    "train_negative_path = r\"C:\\Users\\raziy\\OneDrive\\Masaüstü\\Deep Learning ve Python İleri Seviye Derin Öğrenme (5.1)\\3-DeepResidualNetworks(ResNets)\\LSIFIR\\Classification\\Train\\neg\"\n",
    "num_train_negative_img = 43390\n",
    "train_negative_array = read_images(train_negative_path, num_train_negative_img) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712df57b",
   "metadata": {},
   "source": [
    "Pytorch kütüphanesinin güzel yanlarından birisi, çok sık kullanılan numpy kütüphanesi ile bir arayüzün bulunmasıdır. Yani numpy array'i Pytorch array'e çevirmek mümkündür. Şimdi Pytorch array'e çevirelim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e16a642",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_negative_tensor = torch.from_numpy(train_negative_array)\n",
    "print(\"x_train_negative_tensor:\", x_train_negative_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1665ed",
   "metadata": {},
   "source": [
    "1 boyutlulara vektör, 2 boyutlulara matris, 3 boyutlular, 4 boyutlular, 5 boyutlular vs. bunların hepsine genel olarak tensor denir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_negative_tensor = torch.zeros(num_train_negative_img, dtype = torch.long)\n",
    "print(\"y_train_negatice_tensor:\", y_train_negative_tensor.size())  \n",
    "#pytorch kütüphanesinden 0'lardan oluşan array oluşturdum.\n",
    "#Klasör negatif değerlere ait olduğu için 0'lardan oluşan array'i label olarak nitelendirdik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read train positive folder (10208 sample)\n",
    "train_positive_path = r\"C:\\Users\\raziy\\OneDrive\\Masaüstü\\Deep Learning ve Python İleri Seviye Derin Öğrenme (5.1)\\3-DeepResidualNetworks(ResNets)\\LSIFIR\\Classification\\Train\\pos\"\n",
    "num_train_positive_img = 10208\n",
    "train_positive_array = read_images(train_positive_path, num_train_positive_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_positive_tensor = torch.from_numpy(train_positive_array)\n",
    "print(\"x_train_positive_tensor:\", x_train_positive_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5cdf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_positive_tensor = torch.ones(num_train_positive_img, dtype = torch.long)\n",
    "#Klasör pozitif değerlere ait olduğu için 1'lerdan oluşan array'i label olarak nitelendirdik.\n",
    "print(\"y_train_positive_tensor:\", y_train_positive_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07597d6b",
   "metadata": {},
   "source": [
    "Train setinde pos ve neg klasörleri olduğundan bunları birleştiririz. Mesela 40000 tane positive ve 10000 tane negative var ise bunları yukarıdan aşağıya doğru birleştirerek 50000 tane veriyi Train setinde toplarız. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d65214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat train\n",
    "x_train = torch.cat((x_train_negative_tensor,x_train_positive_tensor),0)\n",
    "y_train = torch.cat((y_train_negative_tensor,y_train_positive_tensor),0)\n",
    "print(\"x_train: \",x_train.size())\n",
    "print(\"y_train: \",y_train.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a825f9c3",
   "metadata": {},
   "source": [
    "torch'un concatenate işlemini yapan metodu cat()'dır.\n",
    "\n",
    "x_train = torch.cat((x_train_negative_tensor, x_train_positive_tensor),0) satırında concatenate yapılacak değişkenler parametre olarak yazılmıştır ve yukarıdan aşağıya birleştirme işlemi yapılacağından 2.parametreye 0 yazılmıştır. Eğer 1 yapsaydık"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3d27f",
   "metadata": {},
   "source": [
    "test seti için birleştirme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db570d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test neg (22050 sample)\n",
    "test_negative_path = r\"C:\\Users\\raziy\\OneDrive\\Masaüstü\\Deep Learning ve Python İleri Seviye Derin Öğrenme (5.1)\\3-DeepResidualNetworks(ResNets)\\LSIFIR\\Classification\\Test\\neg\"\n",
    "num_test_negative_img = 22050\n",
    "test_negative_array = read_images(test_negative_path,num_test_negative_img)\n",
    "x_test_negative_tensor = torch.from_numpy(test_negative_array[:20855,:])\n",
    "print(\"x_test_negative_tensor: \",x_test_negative_tensor.size())\n",
    "y_test_negative_tensor = torch.zeros(20855,dtype = torch.long)\n",
    "print(\"y_test_negative_tensor: \",y_test_negative_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d0a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test positive (5944 sample)\n",
    "test_positive_path = r\"C:\\Users\\raziy\\OneDrive\\Masaüstü\\Deep Learning ve Python İleri Seviye Derin Öğrenme (5.1)\\3-DeepResidualNetworks(ResNets)\\LSIFIR\\Classification\\Test\\pos\"\n",
    "num_test_positive_img = 5944\n",
    "test_positive_array = read_images(test_positive_path,num_test_positive_img)\n",
    "x_test_positive_tensor = torch.from_numpy(test_positive_array)\n",
    "print(\"x_test_positive_tensor: \",x_test_positive_tensor.size())\n",
    "y_test_positive_tensor = torch.zeros(num_test_positive_img,dtype = torch.long)\n",
    "#Klasör pozitif değerlere ait olduğu için 1'lerdan oluşan array'i label olarak nitelendirdik.\n",
    "print(\"y_test_positive_tensor: \",y_test_positive_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat test\n",
    "x_test = torch.cat((x_test_negative_tensor, x_test_positive_tensor), 0)\n",
    "y_test = torch.cat((y_test_negative_tensor, y_test_positive_tensor), 0)\n",
    "print(\"x_test: \",x_test.size())\n",
    "print(\"y_test: \",y_test.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8237cd02",
   "metadata": {},
   "source": [
    "Şimdi görselleştirme yapalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(x_train[45001,:].reshape(64,32), cmap=\"gray\") #bu şekildede yapılabilir.\n",
    "\n",
    "#visualize\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(x_train[45000,:].reshape(64,32), cmap = \"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb181a3",
   "metadata": {},
   "source": [
    "Yukarıdaki görselde insan figürü görülmektedir.\n",
    "\n",
    "    10208. indise kadar olan görüntülerde insan bulunmamaktadır. 10208. indisten sonrasında insan resimleri bulunmaktadır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efac546c",
   "metadata": {},
   "source": [
    "Mesela denizde birisi kayboldu. Denize bir dron gönderdik ve bu dron ayar bantta .alışan bir kameraya sahip değildir. Bu kamera insanı bulamaz. Fakat ayar bantta çalışan bir kamera var ise deniz genelde soğuk olacağı için ve ayar bant kamera ile insanın vücut ısısı görülebileceği için kolay bir şekilde tespit yapılabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe00ac",
   "metadata": {},
   "source": [
    "Artık CNN modeli oluşturabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "num_epochs = 10\n",
    "num_classes = 2\n",
    "batch_size = 8933\n",
    "learning_rate = 0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1f1c9e",
   "metadata": {},
   "source": [
    "Pytorch ile CNN uygulamak için bir tane convolution neural network class'ı oluşturmalıyız.\n",
    "\n",
    "import torch.nn as nn kütüphanesi ile pytorch'un neural network kütüphanesi sağlanmıştır ve nn kısaltması verilmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True )\n",
    "#x_train, y_train -> train datası olarak birleştirilmiştir.\n",
    "#oluşturulan train datası tensor formatındaydı, dataya çevrilip network'e yüklenmiştir.\n",
    "#shuffle=True -> data karıştırılarak eğitilir.\n",
    "\n",
    "test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357b892d",
   "metadata": {},
   "source": [
    "CNN'i hazırladığımıza göre x_train, y_train setleri birleştirilmiştir ve x_test, y_test setleri birleştirilmiştir. Bu işlemi yapma sebebim, x_train ve y_train istediğimiz her şekilde train edilemez. Belirli bir formata uymamız gerekir. Bu formata uymak için de x_train ve y_train'i TensorDataset metodu ile birleştirip train isimli bir değişken elde ederiz. \n",
    "\n",
    "Daha sonra train'i network'e ekleyebilmemiz için trainloader değişkeni tanımlanmıştır. Bu değişkene atanan şey, train'in data'ya çevrilmiş halidir. Bu çevirme işlemi yapılırken eğitim seviyesine hazır hale getirilmesi gerekmektedir. Bu işlem için batch_size'ı belirttik. shuffle=True parametresi ile data'yı karıştırarak eğitimin gerçekleştirilmesi sağlanmıştır.\n",
    "\n",
    "test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False )\n",
    "\n",
    "satırlarında aynı işlemler test için yapılmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b7ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self): \n",
    "\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,10,kernel_size = 5) #1=input, 10=output, 5=5x5'lik feature detector\n",
    "        self.pool = nn.MaxPool2d(2,2)  #max pooling yöntemi ile 2x2'lik matrix feature map üzerinde gezdirilir.\n",
    "        self.conv2 = nn.Conv2d(10,16,kernel_size = 5) #10=input, 16=output, 5=5x5'lik feature detector\n",
    "        \n",
    "        \n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(16*13*5,520) #1.hidden layer\n",
    "        self.fc2 = nn.Linear(520,130)     #2.hidden layer\n",
    "        self.fc3 = nn.Linear(130,num_classes) #output layer\n",
    "\n",
    "    #forward propagation\n",
    "    def forward(self, x): \n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x))) # convolution -> relu -> pooling\n",
    "        x = self.pool(F.relu(self.conv2(x))) # convolution -> relu -> pooling\n",
    "        \n",
    "        x = x.view(-1,16*13*5) #flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "#Böylelikle baştan sona bir step tamamlanmıştır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86604547",
   "metadata": {},
   "source": [
    "class Net(nn.Module): satırı ile nn'in Module'ü inherit edilmiştir. İnherit etmek şudur: Pytorch'dan neural network ile ilgili yapıları kullacağımız anlamına gelir. \n",
    "\n",
    "def __init__(self):\n",
    "        \n",
    "Bu satırda bir constract yani initializer oluşturulmuştur. İnitializer'in içerisine layer'lar, convolutional layer, max pooling, full connected layer gibi neural network yapılarını koyacağız. \n",
    "\n",
    "Daha sonrasında forward propagation yapmalıyız.\n",
    "\n",
    "Yani kullanacağımız yapıları \"def __init__(self)\" metodu içerisinde tanımlayacağız. \"def forward(self, x)\" metodu içerisinde de __init__(self) metodu içeriisnde tanımlanan yapılar sıralanır. Mesela conv->relu->pool->conv->relu... gibi convolutioanl neural network yapısını kurduğum ve layer'ları birbirine bağladığım metodu \"def forward(self, x)\" dur.\n",
    "\n",
    "super(Net,self).__init__() satırın amacı, nn modülünün inheritance'yi gerçekleştirmesidir.\n",
    "\n",
    "self.conv1 = nn.Conv2D(1,10,5) satırında birinci convolutional layer oluşturulmuştur. 1.parametredeki 1 değeri input kanalıdır(channel) . 1.parametredeki 10 değeri output kanalıdır. 3.parametre ile convoluitonal filtrelerinin boyutu 5x5 olarak belirlenmiştir. Yani bu satırda bir tane Conv2D layer tanımlanmıştır ve bunuda conv1 isimli değişkende tutuyoruz.\n",
    "\n",
    "self.conv2 = nn.Conv2D(10,16,5) satırında conv1'den farklı bir hidden layer tasarlanacağı için farklı bir değişkene atanmıştır. Eğer conv1'de tutulan ifadenin aynısı 2 kez kullanılacak ise 2.si için ayrı bir değişkene atamaya gerek yoktur. Bir değişkende tutulan yapı birden fazla kez kullanılabilir.\n",
    "\n",
    "Şimdi fully connected layer kısmını oluşturalım:\n",
    "\n",
    "self.fc1 = nn.Linear(16*13*5, 520) satırında 16*13*5 ifadesi ilk Linear layer'ın inputudur. 520 değeride outputtur.\n",
    "\n",
    "Şimdide forward metodu içerisinde tanımladığımız yapıları sıralayalım:\n",
    "\n",
    "F.relu((self.conv1(x))) kısmı ile conv1 layer'ından sonra 1 tane aktivasyon fonksiyonu relu belirledim.\n",
    "\n",
    "self.pool(F.relu((self.conv1(x)))) kısmı ile pooling yapılmıştır.\n",
    "\n",
    "Klasik CNN'de izlediğimiz yolu uyguladım. Bir tane convolution layer ve daha sonra aktivasyon fonksiyonu ve sonrada pooling koyulmuştur. Ve tüm bu işlemler x'e atanmıştır. \n",
    "\n",
    "def forward(self, x):\n",
    "        x = self.pool(F.relu((self.conv1(x))))\n",
    "        \n",
    "Yani yukarıdaki kısımda forward metoduna input geliyor ve input \"x\" isimli değişkende tutuluyor. Sonrasında input Convolution layer'a giriyor sonrasında relu'ya giriyor ve sonrada pooling uygulanıp tüm bu işlemlerin sonucu x'e eşitleniyor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beb960e",
   "metadata": {},
   "source": [
    "Yukarıda yapılan __init__(self) ve forward(self, x) metodları içerisinde yapılanları şu görsel ile daha iyi anlayabiliriz:\n",
    "\n",
    "<br>\n",
    "<img src=\"r9.png\" align=\"left\" style=\"width:600px;height:400px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5eb4b9",
   "metadata": {},
   "source": [
    "Şimdi convolutional neural network'ü tanımlayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543266dc",
   "metadata": {},
   "source": [
    "Eğer gpu da çalıştıracaksak oluşturduğumuz net değişkenini grafik kartına yollamalıyız. Bunu yapalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03824e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78459f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "import torch.optim as optim \n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa411c08",
   "metadata": {},
   "source": [
    "net.parameters() parametresi ile eğiteceğimiz parametreleri alacak. Yani kullanacağımız weight ve bias değerleri input olarak alınıyor. momentum=0.8 parametresi ile SGD'nin hız ayarı yapılmıştır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ee11e",
   "metadata": {},
   "source": [
    "Artık CNN'i yani net değişkenini eğitebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49865c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a network\n",
    "start = time.time() #başlangıç zamanı tutulur.\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "loss_list = []\n",
    "use_gpu = False #gpu kullanmayacağım için False yaptım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64816b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        #0'dan başlayarak trainloader'daki görsel sayısı kadar döner.\n",
    "        \n",
    "        inputs, labels = data \n",
    "        inputs = inputs.view(batch_size, 1, 64, 32) #1 değeri gray resim olduğunu ifade eder. 64,32 ise resmin size'ını ifade eder.\n",
    "        inputs = inputs.float() \n",
    "        \n",
    "        \n",
    "        #data görselleri ve görsellerin ait olduğu classları(1,0) return eder.\n",
    "        #float'a çevrilir.\n",
    "        # use gpu\n",
    "        if use_gpu:\n",
    "            if torch.cuda.is_available():\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        #zero gradient\n",
    "        optimizer.zero_grad() #her adımda türevler sıfırlanmazsa toplanarak gider..\n",
    "                              #otomatik olarak sıfırlanmaz.\n",
    "        \n",
    "        #forward\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        #loss\n",
    "        loss = criterion(outputs, labels) #output'u label'lar ile karşılaştırarak loss'u buluruz.\n",
    "        \n",
    "        #Loss'u bulduğumuza göre backward propagation yapabiliriz.\n",
    "        loss.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        #test\n",
    "    correct = 0 #ne kadar doğru bilindiği\n",
    "    total = 0   #ne kadar data olduğu\n",
    "    with torch.no_grad(): #no_grad methoduyla back_propagation biter.\n",
    "        \n",
    "        for data in testloader:\n",
    "            images, labels= data\n",
    "            \n",
    "            images = images.view(batch_size,1,64,32)#reshape\n",
    "            images = images.float() #float\n",
    "            \n",
    "            # gpu\n",
    "            if use_gpu:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = net(images)\n",
    "            \n",
    "            #output'un doğru mu yanlış mı olduğunu anlayalım:\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            \n",
    "            #2.parametredeki 1 değeri indekslerin return edildiği anlamına gelmektedir.\n",
    "            total += labels.size(0) #kaç veri bulunduğu üzerine eklenerek gider.\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #Toplam sonucunda sayı çıkmayacak dolayısıyla gerçek bir int sayıya çevirmek için item() metodu kullanılmıştır.\n",
    "            \n",
    "    acc1 = 100*correct/total  # % şeklinde accuracy değeri hesap edilmiştir.\n",
    "    print(\"accuracy test: \",acc1)\n",
    "    test_acc.append(acc1)\n",
    "    \n",
    "    \n",
    "    # #train seti ile test edelim. Yukarıdaki test bloğundaki test ifadelerini train olarak değiştirmek yeterlidir.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            images, labels= data\n",
    "            \n",
    "            #reshape:\n",
    "            images = images.view(batch_size,1,64,32)\n",
    "            images = images.float()\n",
    "            \n",
    "            # gpu\n",
    "            if use_gpu:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = net(images)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    acc2 = 100*(correct/total)\n",
    "    print(\"accuracy train: \",acc2)\n",
    "    train_acc.append(acc2)\n",
    "\n",
    "\n",
    "print(\"train is done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a287608",
   "metadata": {},
   "source": [
    "start = time.time() satırı ile başlangıç zamanının start isimli değişkende tutulması sağlanmıştır.\n",
    "\n",
    "end = time.time() satırı ile bitiş zamanının end isimli değişkende tutulması sağlanmıştır.\n",
    "\n",
    "process_time = (end-start)/60 satırı ile başlangıç ve bitiş arasında geçen zaman hesaplanmıştır.\n",
    "\n",
    "train_acc = []\n",
    "\n",
    "test_acc = []\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "satırlarında accuracy ve loss'u depolamak için listeler tanımladım.\n",
    "\n",
    "for epoch in range(num_epochs): satırında CNN yani net değişkeni data'yı 5000 kez kullanarak train edecek. Yani veriseti üzerinde 5000 kez eğitilecektir.\n",
    "\n",
    "trainloader, train edeceğimiz veri setidir.\n",
    "\n",
    "for i,data in enumerate(trainloader,0):  satırında enumerate ederek 0 ve trainloader'i birleştiriyorum sonrasında index ve data'yı döndürmesini sağlıyorum. indeks (i), trainloader'deki resim sayısı kadar olacak. data ise resimlerin label'larıdır.\n",
    "\n",
    "Data 2 tane shape return ediyor. Birincisi inputs değişkenine atanıyor ve bu değişkende resimler olucak, diğeri ise labels değişkeninde tutulmakta ve içerisinde resimlerin label'ları vardır. İnsan var ise etiketi 1, insan yok ise etiketi 0'dır.\n",
    "\n",
    "Gradients, CNN modelinin öğrenmesini sağlayacak türevlerdir.\n",
    "\n",
    "Başlangıçta gradient'leri yani türevleri sıfırlamalıyız. optimizer.zero_grad() ile gradient'ler sınıflanır.\n",
    "\n",
    "optimizer.step() satırı ile weight'ler yani parametreler update edilmiş oluyor.\n",
    "\n",
    "test data'sında ne kadar doğru bildiğimizi correct değişkeninde tutuyoruz. Ne kadar data olduğunu da total değişkeninde tutuyoruz.\n",
    "\n",
    "train aşamasını bitirip test aşamasına geçtiğimizde with torch.no_grad(): satırı ile backward propagation'un yapılmasını önleriz çünkü eğitim yapmıyoruz artık. \n",
    "\n",
    "Keras'ta yazıyor olsaydık test ve train blokları otomatik olarak yapılacağından yazmaya gerek duymayacaktık. Fakat Pytorch'ta bu kısımları yazmamız gerekmektedir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c155f2",
   "metadata": {},
   "source": [
    "Şimdi Deep Residual Networks kullanarak aynı işlemleri gerçekleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "m = MyModel()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    m.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be07d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image  #Resimleri preprocess yapmak için PIL kütüphanesinden yararlanacağız.\n",
    "import matplotlib.pyplot as plt  #Elde ettiğimiz sonuçları görselleştirmek için marplotlib kütüphanesinden yararlanacağız.\n",
    "import numpy as np\n",
    "import os #os, resimlere ilgili klasörden erişmemizi sağlayacak kütüphanedir.\n",
    "import torch.utils.data  #Data'yı pytorch'a uygun hale getirebilmek için kullanacağımız kütüphanedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device config\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "def read_images(path, num_img):\n",
    "    array = np.zeros([num_img,64*32])\n",
    "    i = 0\n",
    "    for img in os.listdir(path):\n",
    "        img_path = path + \"\\\\\" + img\n",
    "        img = Image.open(img_path, mode = 'r')\n",
    "        data = np.asarray(img,dtype = \"uint8\")\n",
    "        data = data.flatten()\n",
    "        array[i,:] = data\n",
    "        i += 1      \n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f7066",
   "metadata": {},
   "source": [
    "Yukarıdaki blokta bulunan read_images metodu ile gerekli gördüğümüz resimleri, ilgili klasörden okuyup numpy array'e depolama işlemi gerçekleştirilmiştir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a1222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train negative  43390\n",
    "train_negative_path = r\"C:\\Users\\raziy\\OneDrive\\Masaüstü\\Deep Learning ve Python İleri Seviye Derin Öğrenme (5.1)\\3-DeepResidualNetworks(ResNets)\\LSIFIR\\Classification\\Train\\neg\"\n",
    "num_train_negative_img = 43390  #kaç tane resim olduğu \n",
    "train_negative_array = read_images(train_negative_path,num_train_negative_img)\n",
    "x_train_negative_tensor = torch.from_numpy(train_negative_array[:42000,:])\n",
    "print(\"x_train_negative_tensor: \",x_train_negative_tensor.size())\n",
    "y_train_negative_tensor = torch.zeros(42000,dtype = torch.long)\n",
    "print(\"y_train_negative_tensor: \",y_train_negative_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97545ea3",
   "metadata": {},
   "source": [
    "x_train_negative_tensor = torch.from_numpy(train_negative_array[:42000,:]) satırında tensor'a çevirirken tüm resimleri almak yerine sadece başlangıçtan 42000'e kadar olan resimleri alıyoruz.\n",
    "\n",
    "Label'ları oluşturacağımız bir tensor elde etmeliyiz. Bu amaç için \"y_train_negative_tensor = torch.zeros(42000,dtype = torch.long)\" satırı oluşturulmuştur. zeros metodu ile 42000 tane label oluşturulmuştur. zeros metodu ile 42000 tane 0 değeri elde edilir. Zeros metodunun kullanılma sebebi, neg klasörü içerisinde insan olmayan resimler bulunmakta ve bu resimlerin etiketi 0 olarak belirlenmiştir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ba799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train positive 10208\n",
    "train_positive_path = r\"C:\\Users\\raziy\\OneDrive\\Masaüstü\\Deep Learning ve Python İleri Seviye Derin Öğrenme (5.1)\\3-DeepResidualNetworks(ResNets)\\LSIFIR\\Classification\\Train\\pos\"\n",
    "num_train_positive_img = 10208\n",
    "train_positive_array = read_images(train_positive_path,num_train_positive_img)\n",
    "x_train_positive_tensor = torch.from_numpy(train_positive_array[:10000,:]) #0 ile 10000 aralığındaki resimler alınmıştır.\n",
    "print(\"x_train_positive_tensor: \",x_train_positive_tensor.size())\n",
    "y_train_positive_tensor = torch.ones(10000,dtype = torch.long)\n",
    "print(\"y_train_positive_tensor: \",y_train_positive_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05566e9b",
   "metadata": {},
   "source": [
    "y_train_positive_tensor = torch.ones(10000,dtype = torch.long) satırında insan bulunan resimlerin label değerleri oluşturulmuştur. 10000 tane resim olduğundan ve resimlerde insan görselleri bulunduğundan 10000 tane 1 değeri depolanmıştır.\n",
    "\n",
    "Şimdi elde edilen bu array'leri train değişkeninde birleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24450c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat train\n",
    "x_train = torch.cat((x_train_negative_tensor, x_train_positive_tensor), 0)\n",
    "y_train = torch.cat((y_train_negative_tensor, y_train_positive_tensor), 0)\n",
    "print(\"x_train: \",x_train.size())\n",
    "print(\"y_train: \",y_train.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b5f914",
   "metadata": {},
   "source": [
    "Pytorch kütüphanesinde birleştirme işlemi için cat() metodu bulunmaktadır. Yukarıdaki kod bloğunda görüldüğü üzere birleştirme işlemleri gerçekleştirilerek x_train ve y_train değişkenleri elde edilmiştir.\n",
    "\n",
    "Aynı işlemleri test için yapalım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd254a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test negative  22050\n",
    "test_negative_path = r\"C:\\Users\\raziy\\OneDrive\\Masaüstü\\Deep Learning ve Python İleri Seviye Derin Öğrenme (5.1)\\3-DeepResidualNetworks(ResNets)\\LSIFIR\\Classification\\Test\\neg\"\n",
    "num_test_negative_img = 22050\n",
    "test_negative_array = read_images(test_negative_path,num_test_negative_img)\n",
    "x_test_negative_tensor = torch.from_numpy(test_negative_array[:18056,:])\n",
    "print(\"x_test_negative_tensor: \",x_test_negative_tensor.size())\n",
    "y_test_negative_tensor = torch.zeros(18056,dtype = torch.long)\n",
    "print(\"y_test_negative_tensor: \",y_test_negative_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae46fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test positive 5944\n",
    "test_positive_path = r\"C:\\Users\\raziy\\OneDrive\\Masaüstü\\Deep Learning ve Python İleri Seviye Derin Öğrenme (5.1)\\3-DeepResidualNetworks(ResNets)\\LSIFIR\\Classification\\Test\\pos\"\n",
    "num_test_positive_img = 5944\n",
    "test_positive_array = read_images(test_positive_path,num_test_positive_img)\n",
    "x_test_positive_tensor = torch.from_numpy(test_positive_array)\n",
    "print(\"x_test_positive_tensor: \",x_test_positive_tensor.size())\n",
    "y_test_positive_tensor = torch.zeros(num_test_positive_img,dtype = torch.long)\n",
    "print(\"y_test_positive_tensor: \",y_test_positive_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29bd2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat test\n",
    "x_test = torch.cat((x_test_negative_tensor, x_test_positive_tensor), 0)\n",
    "y_test = torch.cat((y_test_negative_tensor, y_test_positive_tensor), 0)\n",
    "print(\"x_test: \",x_test.size())\n",
    "print(\"y_test: \",y_test.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549fb2b",
   "metadata": {},
   "source": [
    "Şimdi görselleştirme yapalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f70d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "plt.imshow(x_train[45001,:].reshape(64,32), cmap='gray') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4f0ae",
   "metadata": {},
   "source": [
    "Şimdi array ve tensor'ü pytorch'a uygun hale getirmeliyiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461220c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2  #insan figürü olan resimler ve insan figürü olmayan resimler şeklinde 2 tane sınıf mevcuttur.\n",
    "# Hyper parameters\n",
    "num_epochs = 100\n",
    "batch_size = 2000\n",
    "learning_rate = 0.0001\n",
    "\n",
    "train = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test = torch.utils.data.TensorDataset(x_test,y_test)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65731fde",
   "metadata": {},
   "source": [
    "train = torch.utils.data.TensorDataset(x_train,y_train) satırında x_train ve y_train birleştirilmiştir. Birleştirme işleminden sonra train isimli tensor elde edilmiştir.\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "Bu satırda, train tensörünü DataLoader isimli metodun içerisine verip, batch_size'ını belirleyip, shuffle değerini True yapıyoruz. Shuffle=True ifadesi, data eğitilirken karıştırılsın anlamına gelmektedir. Birleştirme işlemi yaparken başlarda 0 label'lar ve sonlarda 1 Label'lar şeklinde birleştirme yapmıştık. Bu sıralamanın karışık olmasını sağlamak için shuffle=True yapıyoruz. Ve bu işlemleri trainloader isimli değişkene atıyoruz.\n",
    "\n",
    "test = torch.utils.data.TensorDataset(x_test,y_test)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "Bu iki satırda da aynı işlemler gerçekleştirilmiştir. Fakat shuffle=False ile karıştırma işleminin yapılmaması sağlanmıştır.\n",
    "\n",
    "trainloader ve testloader, pytorch'da data'yı eğitmemiz için gerekli olan yapıyı sağlamaktadır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670819b",
   "metadata": {},
   "source": [
    "Artık deep Residual Networks'ü inşa edelim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f76da",
   "metadata": {},
   "source": [
    "En çok kullanacağımız layer'ları birer metod haline getirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014c142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride = 1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size = 3, stride = stride, padding = 1, bias = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270155c",
   "metadata": {},
   "source": [
    "Metoda verilen conv3x3 isim ile 3x3'lük bir kernel olacağı anlamı ifade edilmiştir. Yani kernel size 3 olacak. \n",
    "\n",
    "out_planes parametresi layer'daki nöron sayısını ifade etmektedir.\n",
    "\n",
    "stride parametresi ile kernel'da yani filtrede tarama yapılırken filtrenin kaçar kaçar ilerleyeceği belirlenmiştir.\n",
    "\n",
    "Padding işleminin yapılma sebebi, resim üzerinde filtre dolaştırıldıktan sonra output resmin boyutundan daha küçük olur ve bu boyutun azalması durumunu engellemek için padding işlemi gerçekleştirilir. Mesela 4x4'lük resim üzerinde 2x2'lik bir filtre dolaştırdığımızda 3x3'lük output elde edilir. Görüldüğü üzere boyutta azalma olmuştur. Resmin orjinal boyutunda output elde edebilmek için padding uygularız. Padding işlemi, resmi temsil eden matrisin kenarlarına 0 eklemektir. Dolayısıyla 4x4 boyutundaki resim 6x6 olur. Ve 6x6'lik matris üzerinde 2x2'lik filtre dolaştırdığımızda output matrisi 5x5 boyutunda olur. Böylelikle resmin orjinal boyutundan daha küçük bir boyutta output elde edilmesi önlenmiştir.\n",
    "\n",
    "<font color=\"CadetBlue\"><br>\n",
    "Output'ta elde edilen matrisin boyutunun orjinal resmi temsil eden matris boyutundan daha az olmasının önlenmesi ile low level layer'lardaki bilgi kaybının engellenmesi sağlanır. Resmin boyutunun azalmasının önlenmesi için padding işlemi kullanılabilir.\n",
    "    \n",
    "batch normalizaton yapılacağı için bias değerine gerek kalmayacaktır. Dolayısıyla bias parametresine False değeri atanmıştır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb520c2e",
   "metadata": {},
   "source": [
    "Kernel size'ı 1x1 olan bir convolutional layer metodu tanımlayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe005a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_planes, out_planes, stride = 1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size = 1, stride = stride, bias = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd1ad8d",
   "metadata": {},
   "source": [
    "Artık basic bloğunu inşa edebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module): \n",
    "#BasicBlok, Pytorch'un neural network Module class'ından inherite edecek. Bunun anlamı, nn.Module içerisindeki her şeyin\n",
    "#kullanılabileceğidir.\n",
    "    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self,inplanes, planes, stride = 1, downsample = None):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)  #Her layer'da normalization yapmak demektir.\n",
    "        self.relu = nn.ReLU(inplace = True)  \n",
    "#inplace = True parametresi ile Relu aktivasyon fonksiyonunu çağırdıktan sonra sonucunun kendisine eşitlenmesi sağlanmıştır.\n",
    "        self.drop = nn.Dropout(0.9) #%90'ının drop yapılması sağlanmıştır.\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    " \n",
    "#Bu kısma kadar basic blok tamamlanmıştır. Şimdi bunları birbirine bağlayalım:\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.drop(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4e40e5",
   "metadata": {},
   "source": [
    "super(BasicBlock,self).__init__() satırında yapılan, BasicBlok'u initialize ediyor yani başlatıyor nn.Module class'ına. Dolayısıyla nn.Module içerisinde bulunanları kullanabiliriz. \n",
    "\n",
    "initialize metodu ile basic bloğunun temel taşlarını oluşturalım.\n",
    "\n",
    "Initalizer içerisinde tanımladığımız katmanlar şu şekildedir:\n",
    "    \n",
    "    convolutional layer \n",
    "    \n",
    "    batch normalization \n",
    "    \n",
    "    Relu \n",
    "    \n",
    "    Stride \n",
    "    \n",
    "    down sample\n",
    "    \n",
    "Bu yapı taşlarını initializer ederek sonrasında forward metodu ile birbirlerine bağladık.\n",
    "\n",
    "<font color=\"DodgerBlue\"><br>\n",
    "Bir cnn mimarisinde Feature Learning katmanlarında Dropout yerine Batch Norm’u tercih edin. Classification katmanlarında ise Dropout kullanabilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db39623",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"r10.png\" align=\"left\" style=\"width:600px;height:400px\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe1b57a",
   "metadata": {},
   "source": [
    "Yukarıdaki görselde bir yukardaki kod bloğunda gerçekleştirilen işlemleri görmektesiniz.\n",
    "\n",
    "Convolutional layer'lar sonucunda x'in boyutu azalmaktadır. Yani ilk başta x'in boyutunun 4x4 olduğunu varsayalım. Sol taraftaki işlemler sonucunda en sonda 2x2'lik matris elde edelim. Sağ taraftan gelen boyut ise 4x4 olacaktır. Ve aşağı tarafta gördüğünüz sağ ve sol taraftan gelen değerlerin toplanması gerekmektedir. Bu iki matris boyutları farklı olduğundan toplanamaz. Dolayısıyla stride=2 ise down sampling işlemi yapılmalıdır.\n",
    "Bu işlemler\n",
    "\n",
    "if self.downsample is not None:\n",
    "\n",
    "            identity = self.downsample(x)\n",
    "            \n",
    "satırlarında gerçekleştirilmiştir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4995c328",
   "metadata": {},
   "source": [
    "Bir sürü basic bloğu birleştirerek Deep Residual Network elde edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccae3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, block, layers, num_classes = num_classes):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride = 2, padding = 3, bias= False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size= 3, stride = 2, padding = 1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "    \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(256*block.expansion, num_classes)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode = \"fan_out\", nonlinearity = \"relu\")\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight,1)\n",
    "                nn.init.constant_(m.bias,0)\n",
    "                \n",
    "    def _make_layer(self, block, planes, blocks, stride = 1):  \n",
    "        #_make_layer metodu ile amaçlanan, basic metodları ard arda koyarak yeni bir yapı oluşturmaktır.\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes*block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                    conv1x1(self.inplanes, planes*block.expansion, stride),\n",
    "                    nn.BatchNorm2d(planes*block.expansion))\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes*block.expansion\n",
    "        for _ in range(1,blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),-1) #Flatten işlemi gerçekleştirilmiştir. Shape değerleri view metodu ile değiştirilmiştir.\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4ef22e",
   "metadata": {},
   "source": [
    "Basic blok yaparken önemli olan nokta downsample olup olmamasıdır yani stride'ın 1 olup olmaması önemlidir. downsample'ı aktive edip etmeyeceğimizi _make_layer metodunda karar vereceğiz.\n",
    "\n",
    "_make_layer iki tane basic bloktan oluşan bir layer'dır.\n",
    "\n",
    "\n",
    "for m in self.modules():\n",
    "\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "            \n",
    "                nn.init.kaiming_normal_(m.weight, mode = \"fan_out\", nonlinearity = \"relu\")\n",
    "                \n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "            \n",
    "                nn.init.constant_(m.weight,1)\n",
    "                \n",
    "                nn.init.constant_(m.bias,0)\n",
    "                \n",
    "                \n",
    "ResNets olduğu için bir sürü layer var. Bu layer'larında weight'leri var. Bu weight'leri mantıklı bir şekilde initializing yapmamız gerekiyor. Eğer mantıksız bir initializing yaparsak vashing problemiyle karşılaşabiliriz. Bu problem öğrenememekle ilgilidir. Yani modelin çalışamaması demektir. Yukarıda belirttiğim kod bloğu ile bu işlem gerçekleştirilmiştir.\n",
    "\n",
    "nn.init.kaiming_normal_(m.weight, mode = \"fan_out\", nonlinearity = \"relu\") satırında sıfıra yakın sayıları weight'lere initial değer olarak atıyor. Bu işlem convolutional layer'da ise gerçekleşiyor.\n",
    "\n",
    "Eğer batch layer'da ise nn.init.constant_(m.weight,1) satırı ile tüm weight'ler 1'e eşitlenir. nn.init.constant_(m.bias,0) satırı ile tüm bias'lar 0'a eşitlenir.\n",
    "\n",
    "Böylelikle Deep Residual Network inşa edilmiştir. Şimdi model oluşturalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7df318",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b4c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(BasicBlock, [2,2,2]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e51075",
   "metadata": {},
   "source": [
    "Şimdi de loss ve optimizer 'ı tanımlayalım. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81082ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01dc235",
   "metadata": {},
   "source": [
    "Artık train kısmına geçebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "loss_list = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "use_gpu = False\n",
    "\n",
    "total_step = len(trainloader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        images = images.view(batch_size,1,64,32)\n",
    "        images = images.float()\n",
    "        \n",
    "        # gpu\n",
    "        if use_gpu:\n",
    "            if torch.cuda.is_available():\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 2 == 0:\n",
    "            print(\"epoch: {} {}/{}\".format(epoch,i,total_step))\n",
    "\n",
    "    # Her epoch'un sonunda sonuçları görmek istiyoruz. Train ve Test setlerine göre sonuçları görelim:\n",
    "    # train\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "            images = images.view(batch_size,1,64,32)\n",
    "            images = images.float()\n",
    "            \n",
    "            # gpu\n",
    "            if use_gpu:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    \n",
    "            outputs = model(images)  #Resimleri modele verip prediction yapılmıştır.\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"Accuracy train %d %%\"%(100*correct/total))\n",
    "    train_acc.append(100*correct/total)\n",
    "\n",
    "    # test\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.view(batch_size,1,64,32)\n",
    "            images = images.float()\n",
    "            \n",
    "            # gpu\n",
    "            if use_gpu:\n",
    "                if torch.cuda.is_available():\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data,1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"Accuracy test %d %%\"%(100*correct/total))\n",
    "    train_acc.append(100*correct/total)\n",
    "\n",
    "    loss_list.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb26ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% visualize\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.plot(loss_list,label = \"Loss\",color = \"black\")\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(np.array(test_acc)/100,label = \"Test Acc\",color=\"green\")\n",
    "ax2.plot(np.array(train_acc)/100,label = \"Train Acc\",color= \"red\")\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax1.set_xlabel('Epoch')\n",
    "fig.tight_layout()\n",
    "plt.title(\"Loss vs Test Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
